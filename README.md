# ğŸ¯ Adversarial-Attack-Simulation-on-Machine-Learning-Models
This project focusses on implementing fundamentals for developing and training machine learning models that respond to adversarial attacks. Specifically, it includes models to detect and evaluate the impact of general adversarial data, evasion attacks, and poisoning attacks.


---

## ğŸ“‚ Project Structure
```plaintext
AI_Project/
â”‚
â”œâ”€â”€ data/                      # Folder to store datasets
â”‚   â””â”€â”€ creditcard.csv
â”œâ”€â”€ adversarial_env/           # Your virtual environment (auto-generated)
â”œâ”€â”€ dataset.py                 # For loading and preprocessing the dataset
â”œâ”€â”€ train.py                   # For training the machine learning model
â”œâ”€â”€ simulate.py                # For simulating adversarial attacks
â”œâ”€â”€ analyze.py                 # For analyzing and visualizing results
â”œâ”€â”€ mitigate.py                # For implementing mitigation strategies
â”œâ”€â”€ utils.py                   # Any utility functions (e.g., common plots)
â”œâ”€â”€ README.md                  # Documentation
â””â”€â”€ main.py                    # The entry point to tie everything together
```

 # ğŸš€ Features

ğŸ§© Dataset Handling: Preprocess the dataset and prepare it for training and evaluation.

ğŸ¤– Model Training: Train machine learning models with clean or adversarially augmented datasets.

ğŸ›¡ï¸ Adversarial Attacks:

Evasion attacks (e.g., FGSM, PGD).

Poisoning attacks to corrupt training data.

ğŸ“Š Analysis & Visualization: Compare original and adversarial data, and evaluate model performance.

ğŸ› ï¸ Mitigation Strategies: Implement defenses to improve robustness against attacks.


# âš¡ Quick Start

## 1ï¸âƒ£ Clone the Repository

$ git clone git@github.com:rianachatterjee04/Adversarial-Attack-Simulation-on-Machine-Learning-Models.git

$ cd Adversarial-Attack-Simulation-on-Machine-Learning-Models

## 2ï¸âƒ£ Set Up the Environment

$ python3 -m venv adversarial_env

$ source adversarial_env/bin/activate

## 3ï¸âƒ£ Download the Dataset

Download the dataset off Kaggle's Credit Card Fraud Detection dataset 

Place the creditcard.csv dataset in the data/ folder.

## 4ï¸âƒ£ Run the Project

Train a Model:

$ python3 train.py

Simulate Adversarial Attacks:

$ python3 simulate.py

Visualize Results:

$ python3 analyze.py


# ğŸ› ï¸ Technologies Used

ğŸ Python: Core programming language.

ğŸ“ˆ NumPy: Numerical computing.

ğŸ—ƒï¸ Pandas: Data manipulation.

ğŸ§  TensorFlow/Keras: Machine learning and deep learning frameworks.

ğŸ”¬ Scikit-learn: Machine learning utilities.

ğŸ›¡ï¸ Adversarial Robustness Toolbox (ART): For simulating adversarial attacks.

ğŸ“Š Matplotlib: Visualization library.

## ğŸ“Š Example Outputs

### Visualization of Adversary Attack
![Adversary Attack Example](Figure_1.png)

###Comparison of Accuracy Scores


### Comparison of Model Accuracy
| **Attack Type**      | **Accuracy** |
|-----------------------|--------------|
| Adversary Attack     | 99.87%       |
| FGSM (Evasion)       | 89.45%       |
| Poisoning Attack     | 74.32%       |





